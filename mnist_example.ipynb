{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 21:56:15.745420: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-15 21:56:15.745455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-15 21:56:15.745482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-15 21:56:15.751615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 21:56:17.020181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.025054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.025311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.027143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.027339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.027504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.103486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.103681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.103848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 21:56:17.103991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2977 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, input_shape = (784,)),\n",
    "    tf.keras.layers.Dense(1024),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 21:56:17.295216: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 376320000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "loss_history = []\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(x_train/255.0, tf.float32),\n",
    "    tf.cast(y_train, tf.int64))\n",
    ")\n",
    "dataset = dataset.shuffle(60000).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  0\n",
      "..........\n",
      "Epoch:  1\n",
      "..........\n",
      "Epoch:  2\n",
      "..........\n",
      "Epoch:  3\n",
      "..........\n",
      "Epoch:  4\n",
      "..........\n",
      "Epoch:  5\n",
      "..........\n",
      "Epoch:  6\n",
      "..........\n",
      "Epoch:  7\n",
      "..........\n",
      "Epoch:  8\n",
      "..........\n",
      "Epoch:  9\n",
      "..........CPU times: user 1min 9s, sys: 1.57 s, total: 1min 11s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    for i in range(10):\n",
    "        print(\"\\nEpoch: \", i)\n",
    "        for (batch, (images, labels)) in enumerate(dataset.take(60000)):\n",
    "            if batch % 100 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "            with tf.GradientTape() as tape:\n",
    "                with tf.device('/device:GPU:0'):\n",
    "                    logits = mnist_model(images, training = True)\n",
    "                with tf.device(\"/cpu:0\"):\n",
    "                    tgmax = tf.argmax(labels, axis = 1, output_type = tf.int64)\n",
    "                with tf.device('/device:GPU:0'):\n",
    "                    loss_value = tf.compat.v1.losses.sparse_softmax_cross_entropy(\n",
    "                        tgmax,\n",
    "                        logits\n",
    "                    )\n",
    "                    loss_history.append(loss_value.numpy())\n",
    "                    grads = tape.gradient(loss_value, mnist_model.variables)\n",
    "                    optimizer.apply_gradients(zip(grads, mnist_model.variables), global_step = tf.compat.v1.train.get_or_create_global_step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  0\n",
      "..........\n",
      "Epoch:  1\n",
      "..........\n",
      "Epoch:  2\n",
      "..........\n",
      "Epoch:  3\n",
      "..........\n",
      "Epoch:  4\n",
      "..........\n",
      "Epoch:  5\n",
      "..........\n",
      "Epoch:  6\n",
      "..........\n",
      "Epoch:  7\n",
      "..........\n",
      "Epoch:  8\n",
      "..........\n",
      "Epoch:  9\n",
      "..........CPU times: user 1min 11s, sys: 1.68 s, total: 1min 13s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    for (batch, (images, labels)) in enumerate(dataset.take(60000)):\n",
    "        if batch % 100 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = mnist_model(images, training = True)\n",
    "            tgmax = tf.argmax(labels, axis = 1, output_type = tf.int64)\n",
    "            loss_value = tf.compat.v1.losses.sparse_softmax_cross_entropy(\n",
    "                tgmax,\n",
    "                logits\n",
    "            )\n",
    "            loss_history.append(loss_value.numpy())\n",
    "            grads = tape.gradient(loss_value, mnist_model.variables)\n",
    "            optimizer.apply_gradients(zip(grads, mnist_model.variables), global_step = tf.compat.v1.train.get_or_create_global_step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.88155, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "probs = tf.nn.softmax(mnist_model(x_train))\n",
    "a = tf.reduce_mean(\n",
    "    tf.cast(\n",
    "        tf.equal(\n",
    "            tf.argmax(probs, axis = 1), \n",
    "            tf.argmax(y_train, axis = 1)\n",
    "        ),\n",
    "        tf.float32)\n",
    "    )\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
