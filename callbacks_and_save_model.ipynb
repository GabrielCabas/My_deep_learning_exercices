{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:32:22.085608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-15 22:32:22.085641: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-15 22:32:22.085668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-15 22:32:22.091550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_labels = train_labels[:5000]\n",
    "test_labels = test_labels[:5000]\n",
    "\n",
    "train_images = train_images[:5000].reshape(-1, 28*28) / 255.0\n",
    "test_images = test_images[:5000].reshape(-1, 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:32:23.364046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.369061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.369316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.371459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.371705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.371869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.458167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.458353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.458511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 22:32:23.458645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1178 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784,), activation=tf.keras.activations.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:32:23.888308: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-15 22:32:24.356603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6c2c05a9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-15 22:32:24.356637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-10-15 22:32:24.360482: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-15 22:32:24.371683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-10-15 22:32:24.435214: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Just finished epoch 0\n",
      "Loss evaluated on the validation dataset= 0.40970560908317566\n",
      "Accuracy reached is 0.8835999965667725\n",
      "\n",
      "Just finished epoch 5\n",
      "Loss evaluated on the validation dataset= 0.25925514101982117\n",
      "Accuracy reached is 0.9261999726295471\n",
      "\n",
      "Just finished epoch 10\n",
      "Loss evaluated on the validation dataset= 0.2509957551956177\n",
      "Accuracy reached is 0.9243999719619751\n",
      "\n",
      "Just finished epoch 15\n",
      "Loss evaluated on the validation dataset= 0.2591657340526581\n",
      "Accuracy reached is 0.932200014591217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6d280c5940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss=tf.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "class CustomCallback1(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        print(logs)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"\\nJust finished epoch\", epoch)\n",
    "            print(\"Loss evaluated on the validation dataset=\", logs.get('val_loss'))\n",
    "            print(\"Accuracy reached is\", logs.get('val_accuracy'))\n",
    "        \n",
    "CC1 = CustomCallback1()\n",
    "model.fit(train_images, train_labels, epochs = 20, validation_data = (test_images, test_labels), callbacks = [CC1], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 2: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 3: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 4: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 5: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 6: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 7: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 8: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 9: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 10: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 11: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 12: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 13: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 14: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 15: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 16: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 17: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 18: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 19: saving model to training/cp.ckpt\n",
      "\n",
      "Epoch 20: saving model to training/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6d1c476610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose = 1\n",
    ")\n",
    "model.fit(train_images, train_labels, epochs = 20, validation_data = (test_images, test_labels), callbacks = [cp_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 901us/step - loss: 2.3962 - accuracy: 0.1336\n",
      "Untrained model accuracy 0.13359999656677246\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, input_shape = (784,), activation=tf.keras.activations.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "model2.compile(optimizer=\"adam\", loss=tf.keras.losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "loss, acc = model2.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 883us/step - loss: 0.3182 - accuracy: 0.9332\n",
      "Restored model accuracy 0.9332000017166138\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights(checkpoint_path)\n",
    "loss, acc = model2.evaluate(test_images, test_labels)\n",
    "print(\"Restored model accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to training_per_epochs/cp-1.ckpt\n",
      "\n",
      "Epoch 2: saving model to training_per_epochs/cp-2.ckpt\n",
      "\n",
      "Epoch 3: saving model to training_per_epochs/cp-3.ckpt\n",
      "\n",
      "Epoch 4: saving model to training_per_epochs/cp-4.ckpt\n",
      "\n",
      "Epoch 5: saving model to training_per_epochs/cp-5.ckpt\n",
      "\n",
      "Epoch 6: saving model to training_per_epochs/cp-6.ckpt\n",
      "\n",
      "Epoch 7: saving model to training_per_epochs/cp-7.ckpt\n",
      "\n",
      "Epoch 8: saving model to training_per_epochs/cp-8.ckpt\n",
      "\n",
      "Epoch 9: saving model to training_per_epochs/cp-9.ckpt\n",
      "\n",
      "Epoch 10: saving model to training_per_epochs/cp-10.ckpt\n",
      "\n",
      "Epoch 11: saving model to training_per_epochs/cp-11.ckpt\n",
      "\n",
      "Epoch 12: saving model to training_per_epochs/cp-12.ckpt\n",
      "\n",
      "Epoch 13: saving model to training_per_epochs/cp-13.ckpt\n",
      "\n",
      "Epoch 14: saving model to training_per_epochs/cp-14.ckpt\n",
      "\n",
      "Epoch 15: saving model to training_per_epochs/cp-15.ckpt\n",
      "\n",
      "Epoch 16: saving model to training_per_epochs/cp-16.ckpt\n",
      "\n",
      "Epoch 17: saving model to training_per_epochs/cp-17.ckpt\n",
      "\n",
      "Epoch 18: saving model to training_per_epochs/cp-18.ckpt\n",
      "\n",
      "Epoch 19: saving model to training_per_epochs/cp-19.ckpt\n",
      "\n",
      "Epoch 20: saving model to training_per_epochs/cp-20.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6cdcb3ad00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_per_epochs/cp-{epoch}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose = 1\n",
    ")\n",
    "model.fit(train_images, train_labels, epochs = 20, validation_data = (test_images, test_labels), callbacks = [cp_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f6cdcb36b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint('training')\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.save(\"entire_model/my_model.h5\")\n",
    "new_model = keras.models.load_model(\"entire_model/my_model.h5\")\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
